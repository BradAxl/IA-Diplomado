{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aprendizaje no supervisado.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqkVVzC5sFFz",
        "colab_type": "text"
      },
      "source": [
        "#Aprendizaje no supervisado\n",
        "\n",
        "El objetivo de este notebook es consolidar el conocimiento sobre los algoritmos de aprendizaje no supervisado revisados en clase. Se realizará experimentación con diversos algoritmos de clusterización y se utilizarán las métricas correspondientes para evaluar su desempeño. \n",
        "\n",
        "El alumno deberá completar las preguntas planetadas en el notebook como parte de la evaluación del curso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGvBY9nEsHBe",
        "colab_type": "text"
      },
      "source": [
        "## K-means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo_-Jp4Lxec2",
        "colab_type": "text"
      },
      "source": [
        "### Clusterización utilizando k-means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmtHxaIiyhli",
        "colab_type": "text"
      },
      "source": [
        "Ejemplo de clusterización en conjunto de datos iris. Se realiza el ajuste del modelo con diferentes valores de k. La gráfica de la inercia muestra cómo esta se reduce a medida que aumenta el valor de k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JcIMrA5ZcCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "inertias = []\n",
        "\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, max_iter = 300, n_init = 10, random_state = 42)\n",
        "    kmeans.fit(X)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    \n",
        "plt.plot(range(1, 11), inertias)\n",
        "plt.title('Inercia por clusters')\n",
        "plt.xlabel('# Clusters')\n",
        "plt.ylabel('Inercia') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnNzRQOwztXR",
        "colab_type": "text"
      },
      "source": [
        "A partir de k = 3 no aumenta mucho la inercia por lo que este es un valor adecuado para el número de clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGcLCvSJy6VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters = 3, max_iter = 300, n_init = 10, random_state = 0)\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "print(\"Inercia: \", kmeans.inertia_)\n",
        "print(\"Score: \",kmeans.score(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWRyXZ_dzdvi",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 1 (1 punto):** ¿Por qué el valor de score es negativo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7VgCtus0dd7",
        "colab_type": "text"
      },
      "source": [
        "Visualizamos los clusters respecto a las dos primeras características."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTHT4nux0XSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 10, c = 'red', label = 'Iris-setosa')\n",
        "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 10, c = 'blue', label = 'Iris-versicolour')\n",
        "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 10, c = 'green', label = 'Iris-virginica')\n",
        "\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 50, c = 'yellow', label = 'Centroids')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7Q77Ztt00R9",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 2 (1 punto):** Muestre la visualización para las otras 2 características (índices 2 y 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-OcV1Fj0_Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Código pregunta 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmkPN8bg4VM4",
        "colab_type": "text"
      },
      "source": [
        "Comparemos la ejecución de Acelerated KMeans (algoritmo por defecto) con Kmeans full."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1l3tnZW1zAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%timeit -n 50 KMeans(algorithm=\"elkan\").fit(X)\n",
        "%timeit -n 50 KMeans(algorithm=\"full\").fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_IOoW6EpB8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X)\n",
        "                for k in range(1, 10)]\n",
        "inertias = [model.inertia_ for model in kmeans_per_k]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnkvtow8dzf6",
        "colab_type": "text"
      },
      "source": [
        "La métrica Silhouette Score permite realizar una mejor evaluación del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_hd6CJphOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "silhouette_scores = [silhouette_score(X, model.labels_)\n",
        "                     for model in kmeans_per_k[1:]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spb68Upcon8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import silhouette_samples\n",
        "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
        "\n",
        "plt.figure(figsize=(11, 9))\n",
        "\n",
        "for k in (2, 3, 4, 5):\n",
        "    plt.subplot(2, 2, k - 1)\n",
        "    \n",
        "    y_pred = kmeans_per_k[k - 1].labels_\n",
        "    silhouette_coefficients = silhouette_samples(X, y_pred)\n",
        "\n",
        "    padding = len(X) // 30\n",
        "    pos = padding\n",
        "    ticks = []\n",
        "    for i in range(k):\n",
        "        coeffs = silhouette_coefficients[y_pred == i]\n",
        "        coeffs.sort()\n",
        "\n",
        "        color = mpl.cm.Spectral(i / k)\n",
        "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "        ticks.append(pos + len(coeffs) // 2)\n",
        "        pos += len(coeffs) + padding\n",
        "\n",
        "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
        "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
        "    if k in (2, 4):\n",
        "        plt.ylabel(\"Cluster\")\n",
        "    \n",
        "    if k in (4, 5):\n",
        "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "        plt.xlabel(\"Silhouette Coefficient\")\n",
        "    else:\n",
        "        plt.tick_params(labelbottom=False)\n",
        "\n",
        "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
        "    plt.title(\"$k={}$\".format(k), fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1HbQoGO1exm",
        "colab_type": "text"
      },
      "source": [
        "Revisemos el score de siluetas para otra distribución de datos:\n",
        "\n",
        "Adaptado del ejemplo de score de siluetas de sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgLXyIKI1sK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "# Generando data de ejemplo usando blobs\n",
        "# El conjunto de datos tiene 3 clusters juntos y uno alejado\n",
        "X, y = make_blobs(n_samples=500,\n",
        "                  n_features=2,\n",
        "                  centers=4,\n",
        "                  cluster_std=1,\n",
        "                  center_box=(-10.0, 10.0),\n",
        "                  shuffle=True,\n",
        "                  random_state=1)  \n",
        "\n",
        "# Se explorará las soluciones para 2 a 6 clusters\n",
        "range_n_clusters = [2, 3, 4, 5, 6]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Se ejecuta el algoritmo KMeans para cada cluster y se genera las etiquetas\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
        "    cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "    # Se utiliza la función silhouette_score para obtener el score de silueta promedio\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\"Para n_clusters =\", n_clusters,\n",
        "          \"El score de silueta promedio es :\", silhouette_avg)\n",
        "\n",
        "    # Se utiliza la función silhouette_samples para obtener el score de cada instancia\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    # Se genera el gráfico de comparación.\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        y_lower = y_upper + 10 \n",
        "\n",
        "    ax1.set_title(\"Gráfico de siluetas para varios clusters\")\n",
        "    ax1.set_xlabel(\"Valor del coeficiente de siluetas\")\n",
        "    ax1.set_ylabel(\"Cluster\")\n",
        "\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([]) \n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"Visualización de los datos clusterizados\")\n",
        "    ax2.set_xlabel(\"Característica 1\")\n",
        "    ax2.set_ylabel(\"Característica 2\")\n",
        "\n",
        "    plt.suptitle((\"Análisis de siluetas para clusterización usando KMeans en datos de prueba\"\n",
        "                  \"con n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsI4ojnT5T3z",
        "colab_type": "text"
      },
      "source": [
        "### Minibatch KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf-vQX689u0K",
        "colab_type": "text"
      },
      "source": [
        "Se puede utilizar un objeto memmap para alimentar un dataset muy grande a la clase MiniBacthKMeans. Esta utiliza un archivo (my_mnist.data en este caso) para almeacenar la data en el disco."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5AwpeAt5TJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist.target = mnist.target.astype(np.int64)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    mnist[\"data\"], mnist[\"target\"], random_state=42)\n",
        "\n",
        "filename = \"my_mnist.data\"\n",
        "X_mm = np.memmap(filename, dtype='float32', mode='write', shape=X_train.shape)\n",
        "X_mm[:] = X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOACbJ5RbCWQ",
        "colab_type": "text"
      },
      "source": [
        "Podemos comparar el tiempo de ejecución de MiniBatchKMeans contra KMeans."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psxFto8g6M4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minibatch_kmeans = MiniBatchKMeans(n_clusters=10, batch_size=10, random_state=42)\n",
        "%timeit minibatch_kmeans.fit(X_mm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbgKYIVIBfmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minibatch_kmeans.score(X_mm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KARxFu4D2oQ",
        "colab_type": "text"
      },
      "source": [
        "**Advertencia:** las siguientes instrucciones pueden demorar unos minutos en ejecutar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwUdcVES8tSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters = 10, random_state=42)\n",
        "%timeit kmeans.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtpYzOFhBewC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans.score(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnAHyRGM9typ",
        "colab_type": "text"
      },
      "source": [
        "### Compresión de imágenes usando KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqKu1atkC3Nt",
        "colab_type": "text"
      },
      "source": [
        "Se utilizará las imágenes de ejemplo de sklearn.datasets. Se normaliza los datos y se utiliza el algoritmo kmeans para agrupar cada pixel en 16 grupos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP5AdBDR9sPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_sample_images\n",
        "\n",
        "# Cargando la imagen de prueba\n",
        "dataset = load_sample_images() \n",
        "A = dataset.images[0] \n",
        "A = np.asarray(A, dtype=float)\n",
        "\n",
        "# Dividir entre 255 para que los valores estén en el rango 0 - 1\n",
        "A = A / 255\n",
        "\n",
        "# Tamaño de la imagen\n",
        "img_size = A.shape\n",
        "\n",
        "# Convertir la imagen en una matrix N x 3, donde N = número de pixels.\n",
        "# Cada fila contiene los valores de Rojo, Verde y Azul\n",
        "# Esto nos da la matriz del conjunto de datos X que usaremos con k-means\n",
        "X = A.reshape((img_size[0] * img_size[1], 3))\n",
        "\n",
        "# Parámetros para el algoritmo KMeans\n",
        "K = 10\n",
        "max_iter = 10\n",
        "kmeans = KMeans(n_clusters = K, random_state=42, max_iter = max_iter)\n",
        "kmeans.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DP4qzBTDfR7",
        "colab_type": "text"
      },
      "source": [
        "Se utiliza los centroides para reconstruir la imagen en base al color de los centroides de cada cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGqTjPu-kHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_recovered =  kmeans.cluster_centers_[kmeans.labels_]\n",
        "\n",
        "# Transformar la imagen recuperada en sus dimensiones originales\n",
        "X_recovered = X_recovered.reshape((img_size[0], img_size[1], 3))\n",
        "\n",
        "# Mostrar la imagen original y la recuperada\n",
        "f, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.axis('off')\n",
        "ax1.imshow(A)\n",
        "ax1.set_title('Original')\n",
        "ax2.axis('off')\n",
        "ax2.imshow(X_recovered)\n",
        "ax2.set_title('Comprimida, con %d colores' % K)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r224cKsE51x",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 3 (2 puntos):** Comprima la imágen de su preferencia. Elija un número de colores que permita preservar los detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWC67P1yJqzA",
        "colab_type": "text"
      },
      "source": [
        "### Segmentacion de imagenes usando KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "964pNB3aK5ea",
        "colab_type": "text"
      },
      "source": [
        "Adaptado de: https://github.com/ageron/handson-ml2.\n",
        "\n",
        "Se clusteriza la imagen para diferentes valores de K. En este caso, K es el número de segmentos deseado. Para separar la imagen de la flor del fondo basta con K = 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuvMZDKeH7NX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = dataset.images[1] \n",
        "\n",
        "# Normalizar imágen\n",
        "A = A / 255\n",
        "\n",
        "X = A.reshape(-1, 3)\n",
        "\n",
        "segmented_imgs = []\n",
        "n_colors = (8, 6, 4, 2)\n",
        "\n",
        "for n_clusters in n_colors:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
        "    segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_imgs.append(segmented_img.reshape(A.shape))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
        "\n",
        "plt.subplot(231)\n",
        "plt.imshow(A)\n",
        "plt.title(\"Original image\")\n",
        "plt.axis('off')\n",
        "\n",
        "for idx, n_clusters in enumerate(n_colors):\n",
        "    plt.subplot(232 + idx)\n",
        "    plt.imshow(segmented_imgs[idx])\n",
        "    plt.title(\"{} colors\".format(n_clusters))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wQYrHGfsI8r",
        "colab_type": "text"
      },
      "source": [
        "## DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKSj_8kKOr14",
        "colab_type": "text"
      },
      "source": [
        "Adaptado de: https://github.com/ageron/handson-ml2\n",
        "\n",
        "\n",
        "Utilizaremos el dataset moons de sklearn. Este contiene dos clases distribuidas en forma de lunas. Visualizamos el conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL1voDkksLWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "X, y = make_moons(n_samples=1000, noise=0.05, random_state=42)\n",
        "\n",
        "plt.scatter(X[y == 0, 0], X[y == 0, 1], s = 5, c = 'red', label = 'Clase 1')\n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1], s = 5, c = 'blue', label = 'Clase 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXQoFSnUO49R",
        "colab_type": "text"
      },
      "source": [
        "Entrenamos dos modelos DBSCAN en los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTHXwBB-O1N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
        "dbscan.fit(X)\n",
        "np.unique(dbscan.labels_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xymGRkiEQMWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbscan2 = DBSCAN(eps=0.2)\n",
        "dbscan2.fit(X)\n",
        "np.unique(dbscan2.labels_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP_rJzPFQmvB",
        "colab_type": "text"
      },
      "source": [
        "Graficamos el resultado de cada ejecución de DBSCAN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz_sf3qMQUoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n",
        "    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
        "    core_mask[dbscan.core_sample_indices_] = True\n",
        "    anomalies_mask = dbscan.labels_ == -1\n",
        "    non_core_mask = ~(core_mask | anomalies_mask)\n",
        "\n",
        "    cores = dbscan.components_\n",
        "    anomalies = X[anomalies_mask]\n",
        "    non_cores = X[non_core_mask]\n",
        "    \n",
        "    plt.scatter(cores[:, 0], cores[:, 1],\n",
        "                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n",
        "    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20, c=dbscan.labels_[core_mask])\n",
        "    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n",
        "                c=\"r\", marker=\"x\", s=100)\n",
        "    plt.scatter(non_cores[:, 0], non_cores[:, 1], c=dbscan.labels_[non_core_mask], marker=\".\")\n",
        "    if show_xlabels:\n",
        "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
        "    else:\n",
        "        plt.tick_params(labelbottom=False)\n",
        "    if show_ylabels:\n",
        "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
        "    else:\n",
        "        plt.tick_params(labelleft=False)\n",
        "    plt.title(\"eps={:.2f}, min_samples={}\".format(dbscan.eps, dbscan.min_samples), fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUAnlL_SQbJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9, 3.2))\n",
        "\n",
        "plt.subplot(121)\n",
        "plot_dbscan(dbscan, X, size=100)\n",
        "\n",
        "plt.subplot(122)\n",
        "plot_dbscan(dbscan2, X, size=600, show_ylabels=False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjlrTx2FQwLh",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 4 (2 puntos):** ¿Qué diferencia hay entre los gráficos de las dos ejecuciones? Explique a que se deben estas diferencias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrOwq35SsOpJ",
        "colab_type": "text"
      },
      "source": [
        "## Birch\n",
        "\n",
        "Se utilizará el algoritmo Birch para realizar la clusterización sobre un conjunto de datos artificial generado con 6 clusters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtsHFsebsO0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from sklearn.cluster import Birch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WgPaW80tvEh",
        "colab_type": "text"
      },
      "source": [
        "Generar el conjunto de datos y graficarlo, se pueden distinguir los 6 clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggu8Fq90_x0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, clusters = make_blobs(n_samples=450, centers=6, cluster_std=0.70, random_state=0)\n",
        "plt.scatter(X[:,0], X[:,1], alpha=0.7, edgecolors='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm6z_Ygbt4Lp",
        "colab_type": "text"
      },
      "source": [
        "Se utiliza la clase Birch para construir el árbol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckfCrsmS_5nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brc = Birch(branching_factor=50, n_clusters=None, threshold=1.5)\n",
        "brc.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15zDy-fIuAeE",
        "colab_type": "text"
      },
      "source": [
        "Con la función predict se puede obtener las etiquetas de cada instancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kxfKQbO_1Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = brc.predict(X)\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw4GqUJ4_-Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[:,0], X[:,1], c=labels, cmap='rainbow', alpha=0.7, edgecolors='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7hwYAEYsJnu",
        "colab_type": "text"
      },
      "source": [
        "Se puede utilizar la función transform para transformar un punto X en su distancia a cada cluster. Estos valores pueden ser utilizados como características adicionales para cada instancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_NuZoQuOLZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_transformed = brc.transform(X)\n",
        "X_transformed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC5m1ULJsLdw",
        "colab_type": "text"
      },
      "source": [
        "## Gaussian Mixture Models\n",
        "\n",
        "Adaptado de: https://github.com/ageron/handson-ml2.\n",
        "\n",
        "Exploraremos diferentes datasets con distribuciones de origen gaussiano para experimentar con el algoritmo GMM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnVp9hf3sOVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1, y1 = make_blobs(n_samples=1000, centers=((4, -4), (0, 0)), random_state=42)\n",
        "X1 = X1.dot(np.array([[0.374, 0.95], [0.732, 0.598]]))\n",
        "X2, y2 = make_blobs(n_samples=250, centers=1, random_state=42)\n",
        "X2 = X2 + [6, -8]\n",
        "X = np.r_[X1, X2]\n",
        "y = np.r_[y1, y2]\n",
        "\n",
        "plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtY6wKgHQwJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "gm = GaussianMixture(n_components=3, n_init=10, random_state=42)\n",
        "gm.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYy8Yrg8RqZ9",
        "colab_type": "text"
      },
      "source": [
        "Se puede utilizar el modelo para generar muestras nuevas de la distribución original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAuJwrW_RGUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new, y_new = gm.sample(100)\n",
        "plt.plot(X_new[:, 0], X_new[:, 1], 'k.', markersize=2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "filM1NGTD1ln",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 5 (2 puntos):** ¿Qué particularidad se puede observar en el gráfico de las muestras generadas? Pruebe generar y graficar un mayor número de muestras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BXj64q_ZTSy",
        "colab_type": "text"
      },
      "source": [
        "Grafiquemos las fronteras de decisión y los contornos de densidad obtenidos por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9f7Ye4VT7i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
        "    if weights is not None:\n",
        "        centroids = centroids[weights > weights.max() / 10]\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "                marker='o', s=30, linewidths=8,\n",
        "                color=circle_color, zorder=10, alpha=0.9)\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "                marker='x', s=50, linewidths=50,\n",
        "                color=cross_color, zorder=11, alpha=1)\n",
        "    \n",
        "def plot_gaussian_mixture(clusterer, X, resolution=1000, show_ylabels=True):\n",
        "    mins = X.min(axis=0) - 0.1\n",
        "    maxs = X.max(axis=0) + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
        "                         np.linspace(mins[1], maxs[1], resolution))\n",
        "    Z = -clusterer.score_samples(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.contourf(xx, yy, Z,\n",
        "                 norm=LogNorm(vmin=1.0, vmax=30.0),\n",
        "                 levels=np.logspace(0, 2, 12))\n",
        "    plt.contour(xx, yy, Z,\n",
        "                norm=LogNorm(vmin=1.0, vmax=30.0),\n",
        "                levels=np.logspace(0, 2, 12),\n",
        "                linewidths=1, colors='k')\n",
        "\n",
        "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contour(xx, yy, Z,\n",
        "                linewidths=2, colors='w', linestyles='dashed')\n",
        "    \n",
        "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
        "    plot_centroids(clusterer.means_, clusterer.weights_)\n",
        "\n",
        "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
        "    if show_ylabels:\n",
        "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
        "    else:\n",
        "        plt.tick_params(labelleft=False)\n",
        "        \n",
        "def compare_gaussian_mixtures(gm1, gm2, X):\n",
        "    plt.figure(figsize=(9, 4))\n",
        "\n",
        "    plt.subplot(121)\n",
        "    plot_gaussian_mixture(gm1, X)\n",
        "    plt.title('covariance_type=\"{}\"'.format(gm1.covariance_type), fontsize=14)\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plot_gaussian_mixture(gm2, X, show_ylabels=False)\n",
        "    plt.title('covariance_type=\"{}\"'.format(gm2.covariance_type), fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y51USLErT9Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plot_gaussian_mixture(gm, X)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR36Dmgf909b",
        "colab_type": "text"
      },
      "source": [
        "Como se vió en clase, es posible restringir las matrices de covarianza usando el parámetro covariance_type:\n",
        "\n",
        "* \"full\" (por defecto): sin restricción, los clusters pueden tomar cualquier forma elipsoidal.\n",
        "* \"tied\": los clusters deben tener la misma forma que puede ser cualquier elipsoide.\n",
        "* \"spherical\": los clusters deben ser esféricos, solo varía el diámetro.\n",
        "* \"diag\": los clusters pueden tener cualquier forma elipsoidal pero los ejes de la elipse deben ser paralelos a los ejes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFZ2rx2M_H_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gm_full = GaussianMixture(n_components=3, n_init=10, covariance_type=\"full\", random_state=42)\n",
        "\n",
        "gm_tied = GaussianMixture(n_components=3, n_init=10, covariance_type=\"tied\", random_state=42)\n",
        "\n",
        "gm_spherical = GaussianMixture(n_components=3, n_init=10, covariance_type=\"spherical\", random_state=42)\n",
        "\n",
        "gm_diag = GaussianMixture(n_components=3, n_init=10, covariance_type=\"diag\", random_state=42)\n",
        "\n",
        "gm_full.fit(X)\n",
        "gm_tied.fit(X)\n",
        "gm_spherical.fit(X)\n",
        "gm_diag.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utvP2t6U_S62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compare_gaussian_mixtures(gm_tied, gm_spherical, X)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZnddYLQ_Vr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compare_gaussian_mixtures(gm_full, gm_diag, X)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-wa87CYAwTa",
        "colab_type": "text"
      },
      "source": [
        "### Detección de anomalías usando GMM\n",
        "\n",
        "\n",
        "GMM puede usarse para detectar anomalías, basta explorar las instancias ubicadas en zonas de baja densidad. Se debe definir un límite de densidad para diferenciar una anomalía. Por ejemplo, si se conoce que 4% es la tasa de productos defectuosos en una fábrica, se puede usar como límite el valor de densidad que mantenga el 4% de instancias fuera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZuq9OptA3f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cálculo del límite de densidad que permite descartar el 4% de las instancias.\n",
        "densities = gm.score_samples(X)\n",
        "density_threshold = np.percentile(densities, 4)\n",
        "anomalies = X[densities < density_threshold]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp9RpDZbDfJC",
        "colab_type": "text"
      },
      "source": [
        "Podemos imprimir las anomalías respecto a las fronteras de decisión y los contornos de densidad obtenidos por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8gO9eHEDNi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plot_gaussian_mixture(gm, X)\n",
        "plt.scatter(anomalies[:, 0], anomalies[:, 1], color='b', marker='x')\n",
        "plt.ylim(top=5.1)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av0kGyEXElxJ",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 6 (2 puntos):** ¿Cuántas instancias se utilizó? ¿Cuántas fueron detectadas como anomalías?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Onw6YHFD9N",
        "colab_type": "text"
      },
      "source": [
        "### GMM: Métricas de evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4CQBYOVFzwm",
        "colab_type": "text"
      },
      "source": [
        "Las métricas de evaluación revisadas para el algoritmo GMM son Bayesian information criterion (BIC) y Akaike information criterion (AIC). Se utilizarán estas métricas para detectar gráficamente el mejor valor de k para el conjunto de datos trabajado previamente. También se utilizará gridsearch para encontrar el mejor valor de k y covariance_type en base a la métrica BIC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddU5K2roGew3",
        "colab_type": "text"
      },
      "source": [
        "Entrenamiento de modelos GMM para k ∈ {1,2,3, ... ,11}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeLaK875FWyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gms_per_k = [GaussianMixture(n_components=k, n_init=10, random_state=42).fit(X)\n",
        "             for k in range(1, 11)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Er6PK3jGZBk",
        "colab_type": "text"
      },
      "source": [
        "Calculo de métricas BIC y AIC para cada modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWYJbgTGFZnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bics = [model.bic(X) for model in gms_per_k]\n",
        "aics = [model.aic(X) for model in gms_per_k]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E939oTMSGxR8",
        "colab_type": "text"
      },
      "source": [
        "Gráfica de los indicadores BIC y AIC para cada valor de k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MBTJ-suFemK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(range(1, 11), bics, \"bo-\", label=\"BIC\")\n",
        "plt.plot(range(1, 11), aics, \"go--\", label=\"AIC\")\n",
        "plt.xlabel(\"$k$\", fontsize=14)\n",
        "plt.ylabel(\"Information Criterion\", fontsize=14)\n",
        "plt.axis([1, 9.5, np.min(aics) - 50, np.max(aics) + 50])\n",
        "plt.annotate('Minimum',\n",
        "             xy=(3, bics[2]),\n",
        "             xytext=(0.35, 0.6),\n",
        "             textcoords='figure fraction',\n",
        "             fontsize=14,\n",
        "             arrowprops=dict(facecolor='black', shrink=0.1)\n",
        "            )\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dujf5bdHG7f9",
        "colab_type": "text"
      },
      "source": [
        "Se utiliza gridsearch para determinar el mejor valor de k y covariance_type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqFMCucqFiDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_bic = np.infty\n",
        "\n",
        "for k in range(1, 11):\n",
        "    for covariance_type in (\"full\", \"tied\", \"spherical\", \"diag\"):\n",
        "        bic = GaussianMixture(n_components=k, n_init=10,\n",
        "                              covariance_type=covariance_type,\n",
        "                              random_state=42).fit(X).bic(X)\n",
        "        if bic < min_bic:\n",
        "            min_bic = bic\n",
        "            best_k = k\n",
        "            best_covariance_type = covariance_type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MErT47pjFwpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_k,best_covariance_type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl8HFOYPHENy",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 7 (2 puntos):** Replique el cálculo de mejores parámetros utilizando la métrica AIC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pr2AAykJVEf",
        "colab_type": "text"
      },
      "source": [
        "### Bayesian Gaussian Mixture Model\n",
        "\n",
        "En vez de realizar una búsqueda manual del número de clusters, se puede utilizar la clase BayesianGaussianMixture. Este modelo parte de un número inicial de componentes (que debe ser mayor al número de clusters) y asigna un peso de 0 a los componentes innecesarios. Podemos volver a experimentar con el conjunto de datos asumiendo que el número de componentes es menor a 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8IfX1f7n_ND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "\n",
        "bgm = BayesianGaussianMixture(n_components=10, n_init=10, random_state=42)\n",
        "bgm.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps38eszbKHlf",
        "colab_type": "text"
      },
      "source": [
        "Si revisamos los pesos del modelo, vemos que ha descartado 7 clusters, manteniendo solo 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYvIYAeFJgWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.round(bgm.weights_, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IoiW-pfKZtd",
        "colab_type": "text"
      },
      "source": [
        "Podemos graficar nuevamente las fronteras de decisión y los contornos de densidad obtenidos por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snt9rhz5JiIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plot_gaussian_mixture(bgm, X)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqcVMf0kEfsY",
        "colab_type": "text"
      },
      "source": [
        "## Comparación de modelos\n",
        "\n",
        "Adaptado de los ejemplos de clusterización de Sklearn.\n",
        "\n",
        "El ejemplo muestra las características de diferentes algoritmos de clusterización en conjuntos de datos 2D de diferentes formas. A excepción del último conjunto de datos, los parámetos de los conjuntos han sido configurados para producir clusters diferenciables. Algunos modelos son más sensibles a ciertas configuraciones que otros.\n",
        "\n",
        "El último conjunto de datos es un ejemplo de datos homogeneos, no tiene solución como problema de clusterizacion. A pesar de que este experimento puede dar luces sobre el comportamiento de cada algoritmo, es posible que este no aplique para conjuntos de datos de dimensionalidad alta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2IidDblEikB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import cluster, datasets, mixture\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import cycle, islice\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# ============\n",
        "# Creación de datasets. Se crean conjuntos de datos de tamaño moderado, que permitan evaluar la \n",
        "# escalabilidad de los algoritmos sin elevar demasiado el tiempo de ejecución.\n",
        "# ============\n",
        "n_samples = 1500\n",
        "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n",
        "                                      noise=.05)\n",
        "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
        "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
        "no_structure = np.random.rand(n_samples, 2), None\n",
        "\n",
        "# Datos con distribución anisotropica \n",
        "random_state = 170\n",
        "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "X_aniso = np.dot(X, transformation)\n",
        "aniso = (X_aniso, y)\n",
        "\n",
        "# Datos con varianzas variadas\n",
        "varied = datasets.make_blobs(n_samples=n_samples,\n",
        "                             cluster_std=[1.0, 2.5, 0.5],\n",
        "                             random_state=random_state)\n",
        "\n",
        "# ============\n",
        "# Parámetros de agrupamiento\n",
        "# ============\n",
        "plt.figure(figsize=(9 * 2 + 3, 12.5))\n",
        "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
        "                    hspace=.01)\n",
        "\n",
        "plot_num = 1\n",
        "\n",
        "default_base = {'quantile': .3,\n",
        "                'eps': .3,\n",
        "                'damping': .9,\n",
        "                'preference': -200,\n",
        "                'n_neighbors': 10,\n",
        "                'n_clusters': 3,\n",
        "                'min_samples': 20,\n",
        "                'xi': 0.05,\n",
        "                'min_cluster_size': 0.1}\n",
        "\n",
        "datasets = [\n",
        "    (noisy_circles, {'damping': .77, 'preference': -240,\n",
        "                     'quantile': .2, 'n_clusters': 2,\n",
        "                     'min_samples': 20, 'xi': 0.25}),\n",
        "    (noisy_moons, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n",
        "    (varied, {'eps': .18, 'n_neighbors': 2,\n",
        "              'min_samples': 5, 'xi': 0.035, 'min_cluster_size': .2}),\n",
        "    (aniso, {'eps': .15, 'n_neighbors': 2,\n",
        "             'min_samples': 20, 'xi': 0.1, 'min_cluster_size': .2}),\n",
        "    (blobs, {}),\n",
        "    (no_structure, {})]\n",
        "\n",
        "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
        "    # Actualización de parámetros para cada dataset\n",
        "    params = default_base.copy()\n",
        "    params.update(algo_params)\n",
        "\n",
        "    X, y = dataset\n",
        "\n",
        "    # Normalización de datos\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "\n",
        "    # Estimacion del ancho de banda requerido por el algoritmo Meanshift\n",
        "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
        "\n",
        "    # Matriz de conectividad requerida por el algoritmo Ward\n",
        "    connectivity = kneighbors_graph(\n",
        "        X, n_neighbors=params['n_neighbors'], include_self=False)\n",
        "    # la matriz de conectividad debe ser simétrica\n",
        "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
        "\n",
        "    # ============\n",
        "    # Creación de modelos de clusterización\n",
        "    # ============\n",
        "    \n",
        "    # Meanshift\n",
        "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
        "    \n",
        "    # Mini Batch KMeans\n",
        "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
        "    \n",
        "    # Ward\n",
        "    ward = cluster.AgglomerativeClustering(\n",
        "        n_clusters=params['n_clusters'], linkage='ward',\n",
        "        connectivity=connectivity)\n",
        "    \n",
        "    # Spectral Clustering\n",
        "    spectral = cluster.SpectralClustering(\n",
        "        n_clusters=params['n_clusters'], eigen_solver='arpack',\n",
        "        affinity=\"nearest_neighbors\")\n",
        "    \n",
        "    # DBSCAN\n",
        "    dbscan = cluster.DBSCAN(eps=params['eps'])\n",
        "    \n",
        "    # OPTICS\n",
        "    optics = cluster.OPTICS(min_samples=params['min_samples'],\n",
        "                            xi=params['xi'],\n",
        "                            min_cluster_size=params['min_cluster_size'])\n",
        "    \n",
        "    # Affinity Propagation\n",
        "    affinity_propagation = cluster.AffinityPropagation(\n",
        "        damping=params['damping'], preference=params['preference'])\n",
        "    \n",
        "    # Agglomerative Clustering\n",
        "    average_linkage = cluster.AgglomerativeClustering(\n",
        "        linkage=\"average\", affinity=\"cityblock\",\n",
        "        n_clusters=params['n_clusters'], connectivity=connectivity)\n",
        "    \n",
        "    # Birch\n",
        "    birch = cluster.Birch(n_clusters=params['n_clusters'])\n",
        "    \n",
        "    # Gaussian Mixture Model\n",
        "    gmm = mixture.GaussianMixture(\n",
        "        n_components=params['n_clusters'], covariance_type='full')\n",
        "\n",
        "    clustering_algorithms = (\n",
        "        ('MiniBatchKMeans', two_means),\n",
        "        ('AffinityPropagation', affinity_propagation),\n",
        "        ('MeanShift', ms),\n",
        "        ('SpectralClustering', spectral),\n",
        "        ('Ward', ward),\n",
        "        ('Agglomerative Clustering', average_linkage),\n",
        "        ('DBSCAN', dbscan),\n",
        "        ('OPTICS', optics),\n",
        "        ('Birch', birch),\n",
        "        ('GaussianMixture', gmm)\n",
        "    )\n",
        "\n",
        "    for name, algorithm in clustering_algorithms:\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Filtro de warnings\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\n",
        "                \"ignore\",\n",
        "                message=\"the number of connected components of the \" +\n",
        "                \"connectivity matrix is [0-9]{1,2}\" +\n",
        "                \" > 1. Completing it to avoid stopping the tree early.\",\n",
        "                category=UserWarning)\n",
        "            warnings.filterwarnings(\n",
        "                \"ignore\",\n",
        "                message=\"Graph is not fully connected, spectral embedding\" +\n",
        "                \" may not work as expected.\",\n",
        "                category=UserWarning)\n",
        "            algorithm.fit(X)\n",
        "\n",
        "        t1 = time.time()\n",
        "        if hasattr(algorithm, 'labels_'):\n",
        "            y_pred = algorithm.labels_.astype(np.int)\n",
        "        else:\n",
        "            y_pred = algorithm.predict(X)\n",
        "\n",
        "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
        "        if i_dataset == 0:\n",
        "            plt.title(name, size=18)\n",
        "\n",
        "        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
        "                                             '#f781bf', '#a65628', '#984ea3',\n",
        "                                             '#999999', '#e41a1c', '#dede00']),\n",
        "                                      int(max(y_pred) + 1))))\n",
        "        # Color negro para outliers, en caso existan\n",
        "        colors = np.append(colors, [\"#000000\"])\n",
        "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
        "\n",
        "        plt.xlim(-2.5, 2.5)\n",
        "        plt.ylim(-2.5, 2.5)\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
        "                 transform=plt.gca().transAxes, size=15,\n",
        "                 horizontalalignment='right')\n",
        "        plot_num += 1\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIkIgEKyRaST",
        "colab_type": "text"
      },
      "source": [
        "## Evaluación\n",
        "**Pregunta 8 (8 puntos):** Elija uno de los conjuntos de datos de la carpeta Clase 7 en el repositorio del curso. Sigua los pasos para realizar el agrupamiento de un conjunto de datos desconocido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0CzGwqTdGJv",
        "colab_type": "text"
      },
      "source": [
        "1) Cargar el dataset seleccionado y explorar los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQRXWFFCJKwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parte 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrIpkLtidK6u",
        "colab_type": "text"
      },
      "source": [
        "2) Exploración gráfica de los puntos para determinar los posibles clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaFlowrDb1Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parte 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtX6Z5gYdUUT",
        "colab_type": "text"
      },
      "source": [
        "3) Realizar cáculos o transformaciones adicionales si el algoritmo lo requiere (ej. normalización)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfjWmLRHUDN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parte 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe7WuEWxdZGl",
        "colab_type": "text"
      },
      "source": [
        "4) Ejecutar alguno de los algoritmos de clusterización y estratégias estudiadas para encontrar el mejor número de clusters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIbByXRDTVIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parte 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqOR4y59dmn_",
        "colab_type": "text"
      },
      "source": [
        "5) Graficar el resultado de la cluterización."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHi1lgByWIY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parte 5"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "SVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOMRZ-hajakb",
        "colab_type": "text"
      },
      "source": [
        "# Clase 4: Support Vector Machines\n",
        "\n",
        "El objetivo de este ejercicio es consolidar la comprensión intuitiva de las SVM, y aprender experimentalmente a ajustar un modelo SVM.\n",
        "\n",
        "*(Original adaptado del curso \"Machine Learning\" de Andrew NG, adaptado del material del curso \"Aprendizaje Automático\" de Cesar Olivares)*\n",
        "\n",
        "## 1. SVM con kernel lineal\n",
        "\n",
        "Empecemos con un conjunto de datos en 2D completamente separable por una frontera de decisión lineal. Importaremos los datos como un [`pandas.DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A8hFPIQjakc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftw9GXWJNF6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget 'https://drive.google.com/uc?export=download&id=19UGsjpICqXoTPqEsNUm7DDBlXkSQKtwl' -O ex6data1.csv\n",
        "!wget 'https://drive.google.com/uc?export=download&id=1ISGGxpdb6YvrvWBCAzDzbUYN22y40oVg' -O ex6data2.csv\n",
        "!wget 'https://drive.google.com/uc?export=download&id=1TTiu1cgekgb4b8YxsNGLM7NQAeUrdFaM' -O ex6data3val.csv\n",
        "!wget 'https://drive.google.com/uc?export=download&id=1Jdz777tTPUf6ctCKe98WX0cjd4Rfsfjk' -O ex6data3train.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j9Q_6AhNCjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = pd.read_csv('ex6data1.csv', names=['x1', 'x2', 'y'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcwkTIQtjakf",
        "colab_type": "text"
      },
      "source": [
        "Siempre es bueno hacernos una idea inicial de los datos. Veamos sus principales parámetros estadísticos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WxrSOGXjakf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostrar estadistica descriptiva\n",
        "data1.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2FBq0fQjaki",
        "colab_type": "text"
      },
      "source": [
        "Veamos ahora los primeros 5 del total de 51 elementos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk98on6jjakj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostrar los primeros 5 elementos del conjunto de datos\n",
        "data1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELSx2M1Ejakl",
        "colab_type": "text"
      },
      "source": [
        "También es posible mostrar fácilmente diagramas de caja:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxlYyAv_jakm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1.boxplot(return_type='axes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB0p_dh0jako",
        "colab_type": "text"
      },
      "source": [
        "Para mayor claridad, separaremos $X$ y $y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qKZXDg6jakp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data1[['x1', 'x2']]\n",
        "y = data1['y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6k6GIowjakr",
        "colab_type": "text"
      },
      "source": [
        "Veamos también la distribución de valores $y$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk0E6nu4jaks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( 'Distribución de valores de y:' )\n",
        "print( data1['y'].value_counts() )\n",
        "\n",
        "data1['y'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1cmLQwojaku",
        "colab_type": "text"
      },
      "source": [
        "Visualicemos $X$ en un diagrama de dispersión, usando colores para distinguir las etiquetas de clase $y \\in [0, 1]$ con los colores rojo $(0)$ y verde $(1)$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQMFIQfDjaku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Conjunto de datos 1')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(X['x1'], X['x2'], c=y, s=30, cmap='prism');\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRV0TKzqjakw",
        "colab_type": "text"
      },
      "source": [
        "En este conjunto de datos, la posición de los ejemplos sugiere una separación natural, un espacio o brecha entre ambos subconjuntos. Sin embargo, se puede observar también un valor atípico positivo en la parte superior izquierda $(0.1, 4.1)$. Como parte de este ejercicio vamos a ver cómo este valor atípico afecta la frontera de decisión de SVM.\n",
        "\n",
        "### Efecto del parámetro $C$\n",
        "\n",
        "En esta parte del ejercicio, vamos a probar ajustar modelos SVM con diferentes valores del parámetro $C$. Cuando $C$ es grande, el modelo SVM tratará de clasificar todos los ejemplos correctamente. $C$ juega un rol similar a $\\frac{1}{\\lambda}$, donde $\\lambda$ es el parámetro de regularización estudiado en la regresión logística.\n",
        "\n",
        "Vamos a usar SVC, que es una implementación del modelo SVM que viene incluida en scikit-learn y está basada en la librería *libsvm*.\n",
        "\n",
        "Usemos en primer lugar un valor $C = 1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSp-Z6vQjakx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC # \"Support vector classifier\"\n",
        "\n",
        "# Ajuste del modelo SVM con C=1\n",
        "model = SVC(kernel='linear', C=1)\n",
        "model.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfL5D69cjak1",
        "colab_type": "text"
      },
      "source": [
        "Para visualizar mejor los datos, definiremos una función de apoyo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tss_6Wknjak2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tomado del libro 'Python Data Science Handbook' de Jake VanderPlas\n",
        "def plot_svc_decision_function(model, ax=None, plot_support=True, levels=[-1, 0, 1], linestyles=['--', '-', '--']):\n",
        "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "    \n",
        "    # create grid to evaluate model\n",
        "    x = np.linspace(xlim[0], xlim[1], 30)\n",
        "    y = np.linspace(ylim[0], ylim[1], 30)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.decision_function(xy).reshape(X.shape)\n",
        "    \n",
        "    # plot decision boundary and margins\n",
        "    ax.contour(X, Y, P, colors='k',\n",
        "               levels=levels, alpha=0.5,\n",
        "               linestyles=linestyles)\n",
        "    \n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oOeFcUnjak5",
        "colab_type": "text"
      },
      "source": [
        "Cuando $C = 1$, se observa que el modelo SVM coloca la frontera de decisión en la brecha que existe entre los dos subconjuntos de datos, y *clasifica mal* el valor atípico de la región superior izquierda. \n",
        "\n",
        "Los vectores de soporte están destacados con un círculo a su alrededor. Son todos aquellos que **no** se encuentran del lado correcto de la frontera de decisión con una distancia $m < 1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7cR5WwXjak5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualización del modelo\n",
        "plt.title('Frontera de decision SVM con C=1 (Conjunto de datos 1)')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(X['x1'], X['x2'], c=y, s=30, cmap='prism');\n",
        "plot_svc_decision_function(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNKHvbLKjak7",
        "colab_type": "text"
      },
      "source": [
        "A continuación, tu tarea es probar diferentes valores de $C$ en este conjunto de datos. Específicamente con los valores $C = 20$ y $C = 100$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFAiutP4jak8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajuste del modelo con C = 20\n",
        "model20 = SVC(kernel='linear', C=20)\n",
        "model20.fit(X, y)\n",
        "\n",
        "# Visualización del modelo\n",
        "plt.title('Frontera de decision SVM con C=20 (Conjunto de datos 1)')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(X['x1'], X['x2'], c=y, s=30, cmap='prism');\n",
        "plot_svc_decision_function(model20) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbrUbQ4Tjak-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajuste del modelo con C = 100\n",
        "model100 = SVC(kernel='linear', C=100)\n",
        "model100.fit(X, y)\n",
        "\n",
        "# Visualización del modelo\n",
        "plt.title('Frontera de decision SVM con C=100 (Conjunto de datos 1)')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(data1['x1'], data1['x2'], c=data1['y'], s=30, cmap='prism');\n",
        "plot_svc_decision_function(model100) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewoUcNKIjak_",
        "colab_type": "text"
      },
      "source": [
        "Contesta las siguientes preguntas en el cuestionario habilitado en la plataforma Paideia:\n",
        "\n",
        "**Pregunta 1:** ¿Cuántos vectores de soporte resultan al entrenar el modelo SVM con un kernel lineal y un valor $C = 20$?\n",
        "\n",
        "**Pregunta 2:** En el modelo con $C = 20$, ¿se clasifica correctamente el valor atípico ubicado en $(0.1, 4.1)$?\n",
        "\n",
        "**Pregunta 3:** ¿Cuántos vectores de soporte resultan al entrenar el modelo SVM con un kernel lineal y un valor $C = 100$?\n",
        "\n",
        "**Pregunta 4:** En el modelo con $C = 100$, ¿se clasifica correctamente el valor atípico ubicado en $(0.1, 4.1)$?\n",
        "\n",
        "**Pregunta 5:** ¿La frontera de decisión del modelo $C = 100$ coincide con la separación natural entre los datos? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL29-rYFjalA",
        "colab_type": "text"
      },
      "source": [
        "## 2. SVM con kernel gaussiano\n",
        "\n",
        "En esta parte del ejercicio usaremos SVMs para clasificación no lineal. Específicamente, usaremos SVMs con kernels gaussianos en conjuntos de datos que no son linealmente separables.\n",
        "\n",
        "### 2.1. Conjunto de datos 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhV3xIiKjalB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = pd.read_csv('ex6data2.csv', names=['x1', 'x2', 'y'])\n",
        "X = data2[['x1', 'x2']]\n",
        "y = data2['y']\n",
        "\n",
        "data2.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7bdg0zvjalD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Conjunto de datos 2')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(X['x1'], X['x2'], c=y, s=10, cmap='prism');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmC94gsijalE",
        "colab_type": "text"
      },
      "source": [
        "Podemos observar que en el conjunto de datos 2 no hay una frontera de decisión lineal que pueda separar los ejemplos positivos y negativos. Sin embargo, usando SVM con kernel gaussiano, se puede aprender una frontera de decisión no lineal que se desempeñe razonablemente bien en este conjunto de datos.\n",
        "\n",
        "Antes de usar un kernel gaussiano, es importante normalizar el conjunto de datos $X$. Si bien en este caso $x_1$ y $x_2$ ya tienen un mismo rango $[0, 1]$, aplicaremos de todos modos un [escalador estándar](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling). El escalador estándar recibe $X$ y registra la media y desviación estándar, las cuales utilizará para transformar los datos. (Comparar con la estadística descriptiva dos pasos más arriba.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYWRlKRfjalF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(X)\n",
        "scaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8_2pp6BjalI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler.mean_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixXTbRfijalM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler.scale_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ73vVBGjalQ",
        "colab_type": "text"
      },
      "source": [
        "Para obtener los datos estandarizados, aplicamos la función `transform`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rZkyaFdjalR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_scaled = scaler.transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Leg21SjalT",
        "colab_type": "text"
      },
      "source": [
        "`X_scaled` es un arreglo `numpy`. Usemos `pandas` para mostrar el sumario estadístico. Podemos verificar que los datos están normalizados con una media $\\mu \\approx 0$ y una desviación estándar $\\sigma \\approx 1$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aFj683OjalU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(X_scaled).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dMsnRCojalX",
        "colab_type": "text"
      },
      "source": [
        "Ahora sí ajustemos el modelo SVM con kernel gaussiano *(Radial Basis Function)*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxmR2lM1jalZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajuste de modelo con kernel gaussiano\n",
        "model = SVC(kernel='rbf', C=1, gamma=50)\n",
        "model.fit(X_scaled, y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RznukAiljalc",
        "colab_type": "text"
      },
      "source": [
        "Haremos la visualización con los datos normalizados. Dado que `X_scaled` es un arreglo `numpy`, accedemos a sus columnas $x_1$ y $x_2$ como `X_scaled[:,0]` y `X_scaled[:,1]`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnXB3oZijald",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualización\n",
        "plt.title('Frontera de decision SVM con kernel gaussiano (Conjunto de datos 2 normalizado)')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(X_scaled[:,0], X_scaled[:,1], c=y, s=10, cmap='prism');\n",
        "plot_svc_decision_function(model, plot_support=False, levels=[0], linestyles=['-']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5W8bSATjalg",
        "colab_type": "text"
      },
      "source": [
        "Por medio del método `score` podemos obtener la exactitud *(accuracy)* del modelo ajustado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK3UJ4yyjalg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.score(X_scaled, y)\n",
        "tasa_de_error = (1- score)\n",
        "n_ejemplos = len(X)\n",
        "n_aciertos = score * len(X) \n",
        "n_errores = n_ejemplos - n_aciertos \n",
        "\n",
        "print ('Total de ejemplos: %d' % n_ejemplos)\n",
        "print ('Exactitud: %0.4f' % score)\n",
        "print ('Tasa de error: %0.4f' % tasa_de_error)\n",
        "print ('Número de ejemplos correctamente clasificados: %d' % n_aciertos)\n",
        "print ('Número de ejemplos incorrectamente clasificados: %d' % n_errores)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKAmZcHhjali",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta 6:** En el modelo ajustado al conjunto de datos 2, ¿cuántos ejemplos fueron correctamente clasificados?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRTg7DeBjalj",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Conjunto de datos 3\n",
        "\n",
        "En esta parte del ejercicio vamos a aprender a seleccionar los parámetros $C$ y $\\gamma$ requeridos por el kernel gaussiano.\n",
        "\n",
        "La selección de los modelos de un parámetro se realiza por medio de *validación cruzada*. Para ello se reserva una muestra aleatoria del conjunto de datos que pueda servir para estimar el grado de generalización de los modelos a evaluar.\n",
        "\n",
        "Para asegurar los mismos resultados, en este ejercicio recibimos directamente el conjunto de entrenamiento `(X, y)` y el conjunto de validación `(Xval, yval)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT-2TeOMjalk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data3train = pd.read_csv('ex6data3train.csv', names=['x1', 'x2', 'y'])\n",
        "X = data3train[['x1', 'x2']]\n",
        "y = data3train['y']\n",
        "\n",
        "data3val = pd.read_csv('ex6data3val.csv', names=['x1', 'x2', 'y'])\n",
        "Xval = data3val[['x1', 'x2']]\n",
        "yval = data3val['y']\n",
        "\n",
        "plt.title('Conjunto de datos 3')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(X['x1'], X['x2'], c=y, s=10, cmap='prism', label='Conjunto de entrenamiento')\n",
        "plt.scatter(Xval['x1'], Xval['x2'], c=yval, marker='x', s=20, cmap='prism', label='Conjunto de validacion')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H7aWS7djalm",
        "colab_type": "text"
      },
      "source": [
        "Realizaremos también la normalización de los datos. Presta atención a que la normalización de los datos de validación $X_{val}$ se debe realizar con los parámetros obtenidos del conjunto de entrenamiento $X$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1olzQNtjaln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = preprocessing.StandardScaler().fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "Xval_scaled = scaler.transform(Xval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR2q3qE-jalp",
        "colab_type": "text"
      },
      "source": [
        "Comparemos la exactitud en los conjuntos de entrenamiento y validación para un modelo con $C=200$ y $\\gamma = 50$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emnPyikSjalq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(kernel='rbf', C=200, gamma=50)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "score_train = model.score(X_scaled, y)\n",
        "score_val = model.score(Xval_scaled, yval)\n",
        "\n",
        "print ('Exactitud en el conjunto de entrenamiento: %0.4f' % score_train)\n",
        "print ('Exactitud en el conjunto de validación: %0.4f' % score_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbIC9u3Ejalr",
        "colab_type": "text"
      },
      "source": [
        "Si bien se tiene una exactitud muy alta en el conjunto de entrenamiento, la exactitud es bastante menor en el conjunto de validación. Este es un síntoma claro de sobreajuste *(overfitting)*. Visualicemos lo que está ocurriendo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oozEsTQnjals",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualización\n",
        "plt.title('SVM con kernel gaussiano (C=200, gamma=50) (Conjunto de datos 3 normalizado)')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.scatter(X_scaled[:,0], X_scaled[:,1], c=y, s=10, cmap='prism', label='Conjunto de entrenamiento')\n",
        "plt.scatter(Xval_scaled[:,0], Xval_scaled[:,1], c=yval, marker='x', s=20, cmap='prism', label='Conjunto de validacion')\n",
        "plot_svc_decision_function(model, plot_support=False, levels=[0], linestyles=['-']) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbADWNf7jalu",
        "colab_type": "text"
      },
      "source": [
        "Podemos apreciar visualmente que la generalización es deficiente porque el modelo está *\"memorizando\"* la ubicación de los valores atípicos. Este no es un comportamiento deseable.\n",
        "\n",
        "Para determinar valores $C$ y $\\gamma$ que brinden una mejor generalización, es necesario probar con diferentes valores, ajustando el modelo en el conjunto de entrenamiento y probando su desempeño en el conjunto de validación. Examina y completa el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYBgfTOBjalv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Cs = np.logspace(-2,2,9)  # ~ [0.01, 0.03, 0.1, ..., 100]\n",
        "gammas = np.logspace(-4,4,9)  # [0.0001, 0.001, ..., 10000]\n",
        "\n",
        "mejor_modelo = None\n",
        "mejor_score = 0\n",
        "for C in Cs:\n",
        "    for gamma in gammas:\n",
        "        \n",
        "        model = SVC(kernel='rbf', C=C, gamma=gamma) \n",
        "        model.fit(X_scaled, y)\n",
        "        \n",
        "        score_val = model.score(Xval_scaled, yval) \n",
        "        \n",
        "        if score_val > mejor_score:\n",
        "            mejor_score = score_val\n",
        "            mejor_modelo = model\n",
        "\n",
        "\n",
        "print ('Mejor valor de C: %0.4f' % mejor_modelo.get_params()['C'])\n",
        "print ('Mejor valor de gamma: %0.4f' % mejor_modelo.get_params()['gamma'])\n",
        "print ('Exactitud en el conjunto de entrenamiento: %0.4f' % mejor_modelo.score(X_scaled, y))\n",
        "print ('Exactitud en el conjunto de validación: %0.4f' % mejor_modelo.score(Xval_scaled, yval))\n",
        "\n",
        "# Visualización\n",
        "plt.title('SVM con kernel gaussiano (Conjunto de datos 3)')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.scatter(X_scaled[:,0], X_scaled[:,1], c=y, s=10, cmap='prism', label='Conjunto de entrenamiento')\n",
        "plt.scatter(Xval_scaled[:,0], Xval_scaled[:,1], c=yval, marker='x', s=20, cmap='prism', label='Conjunto de validacion')\n",
        "plot_svc_decision_function(mejor_modelo, plot_support=False, levels=[0], linestyles=['-']) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU99F5uhjalz",
        "colab_type": "text"
      },
      "source": [
        "Observa la forma de la frontera de decisión de tu mejor modelo y compárala con la obtenida arriba con $C=200$ y $\\gamma = 50$. Luego responde las siguientes preguntas sobre tu mejor modelo:\n",
        "\n",
        "**Pregunta 7:** ¿Cuál fue el mejor valor de $C$ obtenido?\n",
        "\n",
        "**Pregunta 8:** ¿Cuál fue el mejor valor de $\\gamma$ obtenido?\n",
        "\n",
        "**Pregunta 9:** ¿Se obtuvo una mejor exactitud en el conjunto de entrenamiento o en el conjunto de validación?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liVgIArxYTN4",
        "colab_type": "text"
      },
      "source": [
        "# Aplicaciones prácticas: Breast Cancer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHPrfXL4LPHn",
        "colab_type": "text"
      },
      "source": [
        "Carga de datos y separación en conjuntos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44-m0o1FTaXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = load_breast_cancer()\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(data.data, data.target, test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EJJFWxhLV4h",
        "colab_type": "text"
      },
      "source": [
        "Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obahbpSMLYBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "Xtrain = scaler.fit_transform(Xtrain)\n",
        "Xtest = scaler.transform(Xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-SeFq3BLazf",
        "colab_type": "text"
      },
      "source": [
        "Entrenamiento del modelo y obtención del score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXyeNR1VLZ9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(kernel='rbf',C=4., gamma=.05)\n",
        "model.fit(Xtrain, Ytrain)\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "print(\"test score:\", model.score(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jIO5HNOLnd2",
        "colab_type": "text"
      },
      "source": [
        "Exploración de otras métricas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQNJYS_rex9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "Ypred = model.predict(Xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQhCCRNpfpB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(Ytest,Ypred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caKgf7lFLow0",
        "colab_type": "text"
      },
      "source": [
        "Pruebas con kernel linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMvnZDQKLwrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(kernel='linear',C=4.)\n",
        "model.fit(Xtrain, Ytrain)\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "print(\"test score:\", model.score(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kKBRwRmL5jA",
        "colab_type": "text"
      },
      "source": [
        "Pruebas con kernel polinomial de grados 2, 3 y 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfa_bLoZL9mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(kernel='poly',C=4.,degree=2)\n",
        "model.fit(Xtrain, Ytrain)\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "print(\"test score:\", model.score(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JImdLDIMMH7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(kernel='poly',C=4.,degree=3)\n",
        "model.fit(Xtrain, Ytrain)\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "print(\"test score:\", model.score(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NDvp4GHMIGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(kernel='poly',C=4.,degree=4)\n",
        "model.fit(Xtrain, Ytrain)\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "print(\"test score:\", model.score(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN6z0QsAMfzj",
        "colab_type": "text"
      },
      "source": [
        "Pruebas con kernel Sigmoidal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC1GS4uhMMkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SVC(kernel='sigmoid',C=4.,gamma=.05)\n",
        "model.fit(Xtrain, Ytrain)\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "print(\"test score:\", model.score(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aERZqx6NC-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Cs = np.logspace(-2,2,9)  # ~ [0.01, 0.03, 0.1, ..., 100]\n",
        "gammas = np.logspace(-4,4,9)  # [0.0001, 0.001, ..., 10000]\n",
        "\n",
        "mejor_modelo = None\n",
        "mejor_score = 0\n",
        "for C in Cs:\n",
        "    for gamma in gammas:\n",
        "        \n",
        "        model = SVC(kernel='rbf', C=C, gamma=gamma) \n",
        "        model.fit(Xtrain, Ytrain)\n",
        "        \n",
        "        score_val = model.score(Xtest, Ytest) \n",
        "        \n",
        "        if score_val > mejor_score:\n",
        "            mejor_score = score_val\n",
        "            mejor_modelo = model\n",
        "\n",
        "\n",
        "print ('Mejor valor de C: %0.4f' % mejor_modelo.get_params()['C'])\n",
        "print ('Mejor valor de gamma: %0.4f' % mejor_modelo.get_params()['gamma'])\n",
        "print ('Exactitud en el conjunto de entrenamiento: %0.8f' % mejor_modelo.score(Xtrain, Ytrain))\n",
        "print ('Exactitud en el conjunto de validación: %0.8f' % mejor_modelo.score(Xtest, Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}